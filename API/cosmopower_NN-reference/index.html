
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://alessiospuriomancini.github.io/cosmopower/API/cosmopower_NN-reference/">
      
      <link rel="icon" href="../../static/favicon_logo.jpg">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.2.1">
    
    
      
        <title>cosmopower_NN - CosmoPower</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e8d9bf0c.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.e6a45f82.min.css">
        
          
          
          <meta name="theme-color" content="#4051b5">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../static/global.css">
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cosmopower_nn-module" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="CosmoPower" class="md-header__button md-logo" aria-label="CosmoPower" data-md-component="logo">
      
  <img src="../../static/favicon_logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            CosmoPower
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              cosmopower_NN
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="http://github.com/alessiospuriomancini/cosmopower/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    alessiospuriomancini/cosmopower
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="CosmoPower" class="md-nav__button md-logo" aria-label="CosmoPower" data-md-component="logo">
      
  <img src="../../static/favicon_logo.jpg" alt="logo">

    </a>
    CosmoPower
  </label>
  
    <div class="md-nav__source">
      <a href="http://github.com/alessiospuriomancini/cosmopower/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    alessiospuriomancini/cosmopower
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../installation/" class="md-nav__link">
        Installation
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Tutorials and Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tutorials and Examples" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Tutorials and Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1" type="checkbox" id="__nav_3_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1">
          Getting Started
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Getting Started" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          Getting Started
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/getting_started/getting_started_with_cosmopower_NN/getting_started_with_cosmopower_NN/" class="md-nav__link">
        NN emulation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/getting_started/getting_started_with_cosmopower_PCAplusNN/getting_started_with_cosmopower_PCAplusNN/" class="md-nav__link">
        PCA+NN emulation
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_2" type="checkbox" id="__nav_3_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_2">
          Training
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Training" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          Training
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_2_1" type="checkbox" id="__nav_3_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_2_1">
          Data generation
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Data generation" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_2_1">
          <span class="md-nav__icon md-icon"></span>
          Data generation
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/training/data_generation/create_params/" class="md-nav__link">
        Latin Hypercube Sampling the emulator parameters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/training/data_generation/create_spectra/" class="md-nav__link">
        Creating the spectra with a Boltzmann code
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/training/data_generation/format/" class="md-nav__link">
        Preparing the data for training
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/training/NN/training_NN/" class="md-nav__link">
        NN training
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/training/PCAplusNN/training_PCAplusNN/" class="md-nav__link">
        PCA+NN training
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_3" type="checkbox" id="__nav_3_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_3">
          Likelihoods
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Likelihoods" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          Likelihoods
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/likelihoods/tf_planck2018_lite/" class="md-nav__link">
        TensorFlow Planck-lite 2018 likelihood
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../contribute/" class="md-nav__link">
        Contribute/Support/Community
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Code Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Code Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Code Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          cosmopower_NN
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        cosmopower_NN
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#cosmopower.cosmopower_NN" class="md-nav__link">
    cosmopower.cosmopower_NN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cosmopower.cosmopower_NN.cosmopower_NN" class="md-nav__link">
    cosmopower_NN
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cosmopower_PCA-reference/" class="md-nav__link">
        cosmopower_PCA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cosmopower_PCAplusNN-reference/" class="md-nav__link">
        cosmopower_PCAplusNN
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../citation/" class="md-nav__link">
        Citation
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#cosmopower.cosmopower_NN" class="md-nav__link">
    cosmopower.cosmopower_NN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cosmopower.cosmopower_NN.cosmopower_NN" class="md-nav__link">
    cosmopower_NN
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
<a href="http://github.com/alessiospuriomancini/cosmopower/edit/master/docs/API/cosmopower_NN-reference.md" title="Edit this page" class="md-content__button md-icon">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
</a>



<h1 id="cosmopower_nn-module">cosmopower_NN module<a class="headerlink" href="#cosmopower_nn-module" title="Permanent link">&para;</a></h1>


  <div class="doc doc-object doc-module">

<a id="cosmopower.cosmopower_NN"></a>
    <div class="doc doc-contents first">




  <div class="doc doc-children">








  <div class="doc doc-object doc-class">



<h3 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN">
        <code>
cosmopower_NN            (<span title="keras.engine.training.Model">Model</span>)
        </code>



<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Mapping between cosmological parameters and (log)-power spectra</p>

<p><strong>Attributes:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>parameters</code></td>
        <td><code>list [str]</code></td>
        <td><p>model parameters, sorted in the desired order</p></td>
      </tr>
      <tr>
        <td><code>modes</code></td>
        <td><code>numpy.ndarray</code></td>
        <td><p>multipoles or k-values in the (log)-spectra</p></td>
      </tr>
      <tr>
        <td><code>parameters_mean</code></td>
        <td><code>numpy.ndarray</code></td>
        <td><p>mean of input parameters</p></td>
      </tr>
      <tr>
        <td><code>parameters_std</code></td>
        <td><code>numpy.ndarray</code></td>
        <td><p>std of input parameters</p></td>
      </tr>
      <tr>
        <td><code>features_mean</code></td>
        <td><code>numpy.ndarray</code></td>
        <td><p>mean of output features</p></td>
      </tr>
      <tr>
        <td><code>features_std</code></td>
        <td><code>numpy.ndarray</code></td>
        <td><p>std of output features</p></td>
      </tr>
      <tr>
        <td><code>n_hidden</code></td>
        <td><code>list [int]</code></td>
        <td><p>number of nodes for each hidden layer</p></td>
      </tr>
      <tr>
        <td><code>restore</code></td>
        <td><code>bool</code></td>
        <td><p>whether to restore a previously trained model or not</p></td>
      </tr>
      <tr>
        <td><code>restore_filename</code></td>
        <td><code>str</code></td>
        <td><p>filename tag (without suffix) for restoring trained model from file 
(this will be a pickle file with all of the model attributes and weights)</p></td>
      </tr>
      <tr>
        <td><code>trainable</code></td>
        <td><code>bool</code></td>
        <td><p>training layers</p></td>
      </tr>
      <tr>
        <td><code>optimizer</code></td>
        <td><code>tf.keras.optimizers</code></td>
        <td><p>optimizer for training</p></td>
      </tr>
      <tr>
        <td><code>verbose</code></td>
        <td><code>bool</code></td>
        <td><p>whether to print messages at intermediate steps or not</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">cosmopower_NN</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mapping between cosmological parameters and (log)-power spectra</span>

<span class="sd">    Attributes:</span>
<span class="sd">        parameters (list [str]):</span>
<span class="sd">            model parameters, sorted in the desired order</span>
<span class="sd">        modes (numpy.ndarray):</span>
<span class="sd">            multipoles or k-values in the (log)-spectra</span>
<span class="sd">        parameters_mean (numpy.ndarray):</span>
<span class="sd">            mean of input parameters</span>
<span class="sd">        parameters_std (numpy.ndarray):</span>
<span class="sd">            std of input parameters</span>
<span class="sd">        features_mean (numpy.ndarray):</span>
<span class="sd">            mean of output features</span>
<span class="sd">        features_std (numpy.ndarray):</span>
<span class="sd">            std of output features</span>
<span class="sd">        n_hidden (list [int]):</span>
<span class="sd">            number of nodes for each hidden layer</span>
<span class="sd">        restore (bool):</span>
<span class="sd">            whether to restore a previously trained model or not</span>
<span class="sd">        restore_filename (str):</span>
<span class="sd">            filename tag (without suffix) for restoring trained model from file </span>
<span class="sd">            (this will be a pickle file with all of the model attributes and weights)</span>
<span class="sd">        trainable (bool):</span>
<span class="sd">            training layers</span>
<span class="sd">        optimizer (tf.keras.optimizers):</span>
<span class="sd">            optimizer for training</span>
<span class="sd">        verbose (bool):</span>
<span class="sd">            whether to print messages at intermediate steps or not</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                 <span class="n">modes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                 <span class="n">parameters_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                 <span class="n">parameters_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                 <span class="n">features_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                 <span class="n">features_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                 <span class="n">n_hidden</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">],</span> 
                 <span class="n">restore</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                 <span class="n">restore_filename</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                 <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                 <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># super</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">cosmopower_NN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># restore</span>
        <span class="k">if</span> <span class="n">restore</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">restore_filename</span><span class="p">)</span>

        <span class="c1"># else set variables from input arguments</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># attributes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="n">parameters</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">modes</span> <span class="o">=</span> <span class="n">modes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden</span>

            <span class="c1"># architecture</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

            <span class="c1"># input parameters mean and std</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span> <span class="o">=</span> <span class="n">parameters_mean</span> <span class="k">if</span> <span class="n">parameters_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span> <span class="o">=</span> <span class="n">parameters_std</span> <span class="k">if</span> <span class="n">parameters_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="p">)</span>

            <span class="c1"># (log)-spectra mean and std</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span> <span class="o">=</span> <span class="n">features_mean</span> <span class="k">if</span> <span class="n">features_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span> <span class="o">=</span> <span class="n">features_std</span> <span class="k">if</span> <span class="n">features_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">)</span>

        <span class="c1"># input parameters mean and std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;parameters_mean&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;parameters_std&#39;</span><span class="p">)</span>

        <span class="c1"># (log)-spectra mean and std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;features_mean&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;features_std&#39;</span><span class="p">)</span>

        <span class="c1"># weights, biases and activation function parameters for each layer of the network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">betas</span> <span class="o">=</span> <span class="p">[]</span> 
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]],</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;W_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;b_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;alphas_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;betas_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">))</span>

        <span class="c1"># restore weights if restore = True</span>
        <span class="k">if</span> <span class="n">restore</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">betas_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="c1"># optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="o">=</span> <span class="n">verbose</span>

        <span class="c1"># print initialization info, if verbose</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">multiline_str</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Initialized cosmopower_NN model, </span><span class="se">\n</span><span class="s2">&quot;</span> \
                            <span class="sa">f</span><span class="s2">&quot;mapping </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="si">}</span><span class="s2"> input parameters to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="si">}</span><span class="s2"> output modes, </span><span class="se">\n</span><span class="s2">&quot;</span> \
                            <span class="sa">f</span><span class="s2">&quot;using </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)</span><span class="si">}</span><span class="s2"> hidden layers, </span><span class="se">\n</span><span class="s2">&quot;</span> \
                            <span class="sa">f</span><span class="s2">&quot;with </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)</span><span class="si">}</span><span class="s2"> nodes, respectively. </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">multiline_str</span><span class="p">)</span>


<span class="c1"># ========== TENSORFLOW implementation ===============</span>

    <span class="c1"># non-linear activation function</span>
    <span class="k">def</span> <span class="nf">activation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                   <span class="n">x</span><span class="p">,</span> 
                   <span class="n">alpha</span><span class="p">,</span> 
                   <span class="n">beta</span>
                   <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Non-linear activation function</span>

<span class="sd">        Parameters:</span>
<span class="sd">            x (Tensor):</span>
<span class="sd">                linear output from previous layer</span>
<span class="sd">            alpha (Tensor):</span>
<span class="sd">                trainable parameter</span>
<span class="sd">            beta (Tensor):</span>
<span class="sd">                trainable parameter</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor:</span>
<span class="sd">                the result of applying the non-linear activation function to the linear output of the layer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">x</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">beta</span><span class="p">))</span> <span class="p">),</span> <span class="n">x</span><span class="p">)</span>


    <span class="c1"># tensor predictions</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">predictions_tf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                       <span class="n">parameters_tensor</span>
                       <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prediction given tensor of input parameters,</span>
<span class="sd">        fully implemented in TensorFlow</span>

<span class="sd">        Parameters:</span>
<span class="sd">            parameters_tensor (Tensor):</span>
<span class="sd">                input parameters</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor:</span>
<span class="sd">                output predictions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">parameters_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>

            <span class="c1"># linear network operation</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

            <span class="c1"># non-linear activation function</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

        <span class="c1"># linear output layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

        <span class="c1"># rescale -&gt; output predictions</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_std</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span><span class="p">)</span>


    <span class="c1"># tensor 10.**predictions</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">ten_to_predictions_tf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                           <span class="n">parameters_tensor</span>
                           <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        10^predictions given tensor of input parameters,</span>
<span class="sd">        fully implemented in TensorFlow. It raises 10 to the output</span>
<span class="sd">        of ``predictions_tf``</span>

<span class="sd">        Parameters:</span>
<span class="sd">            parameters_tensor (Tensor):</span>
<span class="sd">                input parameters</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor:</span>
<span class="sd">                10^output predictions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictions_tf</span><span class="p">(</span><span class="n">parameters_tensor</span><span class="p">))</span>


<span class="c1"># ============= SAVE/LOAD model =============</span>

    <span class="c1"># save network parameters to Numpy arrays</span>
    <span class="k">def</span> <span class="nf">update_emulator_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update emulator parameters before saving them</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># put network parameters to numpy arrays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">betas_</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>

        <span class="c1"># put mean and std parameters to numpy arrays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_std</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>


    <span class="c1"># save</span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
             <span class="n">filename</span>
             <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save network parameters</span>

<span class="sd">        Parameters:</span>
<span class="sd">            filename (str):</span>
<span class="sd">                filename tag (without suffix) where model will be saved</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># attributes</span>
        <span class="n">attributes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> 
                      <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">,</span> 
                      <span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span><span class="p">,</span> 
                      <span class="bp">self</span><span class="o">.</span><span class="n">betas_</span><span class="p">,</span> 
                      <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span><span class="p">,</span> 
                      <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">modes</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">]</span>

        <span class="c1"># save attributes to file</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;.pkl&quot;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">attributes</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>


    <span class="c1"># restore attributes</span>
    <span class="k">def</span> <span class="nf">restore</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                <span class="n">filename</span>
                <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load pre-trained model</span>

<span class="sd">        Parameters:</span>
<span class="sd">            filename (str):</span>
<span class="sd">                filename tag (without suffix) where model was saved</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># load attributes</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;.pkl&quot;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas_</span><span class="p">,</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span><span class="p">,</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span><span class="p">,</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">modes</span><span class="p">,</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>


<span class="c1"># ========== NUMPY implementation ===============</span>

    <span class="c1"># auxiliary function to sort input parameters</span>
    <span class="k">def</span> <span class="nf">dict_to_ordered_arr_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                               <span class="n">input_dict</span><span class="p">,</span> 
                               <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sort input parameters</span>

<span class="sd">        Parameters:</span>
<span class="sd">            input_dict (dict [numpy.ndarray]):</span>
<span class="sd">                input dict of (arrays of) parameters to be sorted</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray:</span>
<span class="sd">                parameters sorted according to desired order</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">input_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">input_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">input_dict</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


    <span class="c1"># forward prediction given input parameters implemented in Numpy</span>
    <span class="k">def</span> <span class="nf">forward_pass_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                        <span class="n">parameters_arr</span>
                        <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the network to predict the output, </span>
<span class="sd">        fully implemented in Numpy</span>

<span class="sd">        Parameters:</span>
<span class="sd">            parameters_arr (numpy.ndarray):</span>
<span class="sd">                array of input parameters</span>

<span class="sd">        Returns:</span>
<span class="sd">          numpy.ndarray:</span>
<span class="sd">            output predictions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># forward pass through the network</span>
        <span class="n">act</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[(</span><span class="n">parameters_arr</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>

            <span class="c1"># linear network operation</span>
            <span class="n">act</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

            <span class="c1"># pass through activation function</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">betas_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">betas_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">*</span><span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="mf">1.</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">act</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span><span class="o">*</span><span class="n">act</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># final (linear) layer -&gt; (standardised) predictions</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># rescale and output</span>
        <span class="k">return</span> <span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span>


    <span class="c1"># Numpy array predictions</span>
    <span class="k">def</span> <span class="nf">predictions_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                       <span class="n">parameters_dict</span>
                       <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predictions given input parameters collected in a dict.</span>
<span class="sd">        Fully implemented in Numpy. Calls ``forward_pass_np``</span>
<span class="sd">        after ordering the input parameter dict</span>

<span class="sd">        Parameters:</span>
<span class="sd">            parameters_dict (dict [numpy.ndarray]):</span>
<span class="sd">                dictionary of (arrays of) parameters</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray:</span>
<span class="sd">                output predictions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parameters_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dict_to_ordered_arr_np</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_pass_np</span><span class="p">(</span><span class="n">parameters_arr</span><span class="p">)</span>


    <span class="c1"># Numpy array 10.**predictions</span>
    <span class="k">def</span> <span class="nf">ten_to_predictions_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                            <span class="n">parameters_dict</span>
                            <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        10^predictions given input parameters collected in a dict.</span>
<span class="sd">        Fully implemented in Numpy. It raises 10 to the output</span>
<span class="sd">        from ``forward_pass_np``</span>

<span class="sd">        Parameters:</span>
<span class="sd">            parameters_dict (dict [numpy.ndarray]):</span>
<span class="sd">                dictionary of (arrays of) parameters</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray:</span>
<span class="sd">                10^output predictions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">10.</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">predictions_np</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">)</span>



    <span class="c1">### Infrastructure for network training ###</span>

    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                     <span class="n">training_parameters</span><span class="p">,</span>
                     <span class="n">training_features</span>
                     <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Mean squared difference</span>

<span class="sd">        Parameters:</span>
<span class="sd">            training_parameters (Tensor):</span>
<span class="sd">                input parameters</span>
<span class="sd">            training_features (Tensor):</span>
<span class="sd">                true features</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor:</span>
<span class="sd">                mean squared difference</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">squared_difference</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictions_tf</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">),</span> <span class="n">training_features</span><span class="p">)))</span>


    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">compute_loss_and_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                                   <span class="n">training_parameters</span><span class="p">,</span>
                                   <span class="n">training_features</span>
                                   <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes mean squared difference and gradients</span>

<span class="sd">        Parameters:</span>
<span class="sd">            training_parameters (Tensor):</span>
<span class="sd">                input parameters</span>
<span class="sd">            training_features (Tensor):</span>
<span class="sd">                true features</span>

<span class="sd">        Returns:</span>
<span class="sd">            loss (Tensor):</span>
<span class="sd">                mean squared difference</span>
<span class="sd">            gradients (Tensor):</span>
<span class="sd">                gradients</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute loss on the tape</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>

            <span class="c1"># loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">squared_difference</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictions_tf</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">),</span> <span class="n">training_features</span><span class="p">)))</span> 

        <span class="c1"># compute gradients</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">gradients</span>


    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                      <span class="n">training_parameters</span><span class="p">,</span>
                      <span class="n">training_features</span>
                      <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Minimize loss</span>

<span class="sd">        Parameters:</span>
<span class="sd">            training_parameters (Tensor):</span>
<span class="sd">                input parameters</span>
<span class="sd">            training_features (Tensor):</span>
<span class="sd">                true features</span>

<span class="sd">        Returns:</span>
<span class="sd">            loss (Tensor):</span>
<span class="sd">                mean squared difference</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute loss and gradients</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">gradients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss_and_gradients</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">,</span> <span class="n">training_features</span><span class="p">)</span>

        <span class="c1"># apply gradients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">loss</span>


    <span class="k">def</span> <span class="nf">training_step_with_accumulated_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                                                 <span class="n">training_parameters</span><span class="p">,</span> 
                                                 <span class="n">training_features</span><span class="p">,</span> 
                                                 <span class="n">accumulation_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Minimize loss, breaking calculation into accumulated gradients</span>

<span class="sd">        Parameters:</span>
<span class="sd">            training_parameters (Tensor):</span>
<span class="sd">                input parameters</span>
<span class="sd">            training_features (Tensor):</span>
<span class="sd">                true features</span>
<span class="sd">            accumulation_steps (int):</span>
<span class="sd">                number of accumulated gradients</span>

<span class="sd">        Returns:</span>
<span class="sd">            accumulated_loss (Tensor):</span>
<span class="sd">                mean squared difference</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># create dataset to do sub-calculations over</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">training_parameters</span><span class="p">,</span> <span class="n">training_features</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">training_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">accumulation_steps</span><span class="p">))</span>

        <span class="c1"># initialize gradients and loss (to zero)</span>
        <span class="n">accumulated_gradients</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">variable</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">variable</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">]</span>
        <span class="n">accumulated_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># loop over sub-batches</span>
        <span class="k">for</span> <span class="n">training_parameters_</span><span class="p">,</span> <span class="n">training_features_</span><span class="p">,</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>

            <span class="c1"># calculate loss and gradients</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">gradients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss_and_gradients</span><span class="p">(</span><span class="n">training_parameters_</span><span class="p">,</span> <span class="n">training_features_</span><span class="p">)</span>

            <span class="c1"># update the accumulated gradients and loss</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">accumulated_gradients</span><span class="p">)):</span>
                <span class="n">accumulated_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">training_features_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">training_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">accumulated_loss</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="n">loss</span><span class="o">*</span><span class="n">training_features_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">training_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="c1"># apply accumulated gradients</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">accumulated_gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">accumulated_loss</span>


<span class="c1"># ==========================================</span>
<span class="c1">#         main TRAINING function</span>
<span class="c1"># ==========================================</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
              <span class="n">training_parameters</span><span class="p">,</span>
              <span class="n">training_features</span><span class="p">,</span>
              <span class="n">filename_saved_model</span><span class="p">,</span>
              <span class="c1"># cooling schedule</span>
              <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
              <span class="n">learning_rates</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">],</span>
              <span class="n">batch_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">],</span>
              <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
              <span class="c1"># early stopping set up</span>
              <span class="n">patience_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
              <span class="n">max_epochs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span>
             <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the model</span>

<span class="sd">        Parameters:</span>
<span class="sd">            training_parameters (dict [numpy.ndarray]):</span>
<span class="sd">                input parameters</span>
<span class="sd">            training_features (numpy.ndarray):</span>
<span class="sd">                true features for training</span>
<span class="sd">            filename_saved_model (str):</span>
<span class="sd">                filename tag where model will be saved</span>
<span class="sd">            validation_split (float):</span>
<span class="sd">                percentage of training data used for validation</span>
<span class="sd">            learning_rates (list [float]):</span>
<span class="sd">                learning rates for each step of learning schedule</span>
<span class="sd">            batch_sizes (list [int]):</span>
<span class="sd">                batch sizes for each step of learning schedule</span>
<span class="sd">            gradient_accumulation_steps (list [int]):</span>
<span class="sd">                batches for gradient accumulations for each step of learning schedule</span>
<span class="sd">            patience_values (list [int]):</span>
<span class="sd">                early stopping patience for each step of learning schedule</span>
<span class="sd">            max_epochs (list [int]):</span>
<span class="sd">                maximum number of epochs for each step of learning schedule</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># check correct number of steps</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">)</span>\
               <span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">gradient_accumulation_steps</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">patience_values</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">),</span> \
               <span class="s1">&#39;Number of learning rates, batch sizes, gradient accumulation steps, patience values and max epochs are not matching!&#39;</span>

        <span class="c1"># training start info, if verbose</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">multiline_str</span> <span class="o">=</span> <span class="s2">&quot;Starting cosmopower_NN training, </span><span class="se">\n</span><span class="s2">&quot;</span> \
                            <span class="sa">f</span><span class="s2">&quot;using </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">validation_split</span><span class="p">)</span><span class="si">}</span><span class="s2"> per cent of training samples for validation. </span><span class="se">\n</span><span class="s2">&quot;</span> \
                            <span class="sa">f</span><span class="s2">&quot;Performing </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)</span><span class="si">}</span><span class="s2"> learning steps, with </span><span class="se">\n</span><span class="s2">&quot;</span> \
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)</span><span class="si">}</span><span class="s2"> learning rates </span><span class="se">\n</span><span class="s2">&quot;</span> \
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">)</span><span class="si">}</span><span class="s2"> batch sizes </span><span class="se">\n</span><span class="s2">&quot;</span> \
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">gradient_accumulation_steps</span><span class="p">)</span><span class="si">}</span><span class="s2"> gradient accumulation steps </span><span class="se">\n</span><span class="s2">&quot;</span> \
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">patience_values</span><span class="p">)</span><span class="si">}</span><span class="s2"> patience values </span><span class="se">\n</span><span class="s2">&quot;</span> \
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">)</span><span class="si">}</span><span class="s2"> max epochs </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">multiline_str</span><span class="p">)</span>

        <span class="c1"># from dict to array</span>
        <span class="n">training_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dict_to_ordered_arr_np</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">)</span>

        <span class="c1"># parameters standardisation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># features standardisation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">training_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">training_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># input parameters mean and std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;parameters_mean&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;parameters_std&#39;</span><span class="p">)</span>

        <span class="c1"># (log)-spectra mean and std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;features_mean&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_std</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;features_std&#39;</span><span class="p">)</span>

        <span class="c1"># training/validation split</span>
        <span class="n">n_validation</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">training_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">validation_split</span><span class="p">)</span>
        <span class="n">n_training</span> <span class="o">=</span> <span class="n">training_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">n_validation</span>

        <span class="c1"># casting</span>
        <span class="n">training_parameters</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">training_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">training_features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># train using cooling/heating schedule for lr/batch-size</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)):</span>

            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;learning rate = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;, batch size = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

            <span class="c1"># set learning rate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># split into validation and training sub-sets</span>
            <span class="n">training_selection</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">([</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_training</span> <span class="o">+</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_validation</span><span class="p">)</span>

            <span class="c1"># create iterable dataset (given batch size)</span>
            <span class="n">training_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">training_parameters</span><span class="p">[</span><span class="n">training_selection</span><span class="p">],</span> <span class="n">training_features</span><span class="p">[</span><span class="n">training_selection</span><span class="p">]))</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">n_training</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

            <span class="c1"># set up training loss</span>
            <span class="n">training_loss</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">infty</span><span class="p">]</span>
            <span class="n">validation_loss</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">infty</span><span class="p">]</span>
            <span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">infty</span>
            <span class="n">early_stopping_counter</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># loop over epochs</span>
            <span class="k">with</span> <span class="n">trange</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>
                    <span class="c1"># loop over batches</span>
                    <span class="k">for</span> <span class="n">theta</span><span class="p">,</span> <span class="n">feats</span> <span class="ow">in</span> <span class="n">training_data</span><span class="p">:</span>

                        <span class="c1"># training step: check whether to accumulate gradients or not (only worth doing this for very large batch sizes)</span>
                        <span class="k">if</span> <span class="n">gradient_accumulation_steps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_step</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">feats</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_step_with_accumulated_gradients</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">feats</span><span class="p">,</span> <span class="n">accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                    <span class="c1"># compute validation loss at the end of the epoch</span>
                    <span class="n">validation_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">[</span><span class="o">~</span><span class="n">training_selection</span><span class="p">],</span> <span class="n">training_features</span><span class="p">[</span><span class="o">~</span><span class="n">training_selection</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

                    <span class="c1"># update the progressbar</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">validation_loss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                    <span class="c1"># early stopping condition</span>
                    <span class="k">if</span> <span class="n">validation_loss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
                        <span class="n">best_loss</span> <span class="o">=</span> <span class="n">validation_loss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                        <span class="n">early_stopping_counter</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">early_stopping_counter</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">if</span> <span class="n">early_stopping_counter</span> <span class="o">&gt;=</span> <span class="n">patience_values</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">update_emulator_parameters</span><span class="p">()</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename_saved_model</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation loss = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">best_loss</span><span class="p">))</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model saved.&#39;</span><span class="p">)</span>
                        <span class="k">break</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_emulator_parameters</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename_saved_model</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Reached max number of epochs. Validation loss = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">best_loss</span><span class="p">))</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model saved.&#39;</span><span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.__init__">
<code class="codehilite language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">modes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">parameters_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">parameters_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">features_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">features_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">],</span> <span class="n">restore</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">restore_filename</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=&lt;</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizer_v2</span><span class="o">.</span><span class="n">adam</span><span class="o">.</span><span class="n">Adam</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7f9f759f6b10</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.__init__" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Constructor</p>

        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
             <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
             <span class="n">modes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
             <span class="n">parameters_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
             <span class="n">parameters_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
             <span class="n">features_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
             <span class="n">features_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
             <span class="n">n_hidden</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">],</span> 
             <span class="n">restore</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
             <span class="n">restore_filename</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
             <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
             <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
             <span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># super</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">cosmopower_NN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># restore</span>
    <span class="k">if</span> <span class="n">restore</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">restore_filename</span><span class="p">)</span>

    <span class="c1"># else set variables from input arguments</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="n">parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modes</span> <span class="o">=</span> <span class="n">modes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden</span>

        <span class="c1"># architecture</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># input parameters mean and std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span> <span class="o">=</span> <span class="n">parameters_mean</span> <span class="k">if</span> <span class="n">parameters_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span> <span class="o">=</span> <span class="n">parameters_std</span> <span class="k">if</span> <span class="n">parameters_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="p">)</span>

        <span class="c1"># (log)-spectra mean and std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span> <span class="o">=</span> <span class="n">features_mean</span> <span class="k">if</span> <span class="n">features_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span> <span class="o">=</span> <span class="n">features_std</span> <span class="k">if</span> <span class="n">features_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">)</span>

    <span class="c1"># input parameters mean and std</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;parameters_mean&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;parameters_std&#39;</span><span class="p">)</span>

    <span class="c1"># (log)-spectra mean and std</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;features_mean&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;features_std&#39;</span><span class="p">)</span>

    <span class="c1"># weights, biases and activation function parameters for each layer of the network</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">betas</span> <span class="o">=</span> <span class="p">[]</span> 
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]],</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;W_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;b_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;alphas_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;betas_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">))</span>

    <span class="c1"># restore weights if restore = True</span>
    <span class="k">if</span> <span class="n">restore</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">betas_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="c1"># optimizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="o">=</span> <span class="n">verbose</span>

    <span class="c1"># print initialization info, if verbose</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="n">multiline_str</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Initialized cosmopower_NN model, </span><span class="se">\n</span><span class="s2">&quot;</span> \
                        <span class="sa">f</span><span class="s2">&quot;mapping </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="si">}</span><span class="s2"> input parameters to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="si">}</span><span class="s2"> output modes, </span><span class="se">\n</span><span class="s2">&quot;</span> \
                        <span class="sa">f</span><span class="s2">&quot;using </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)</span><span class="si">}</span><span class="s2"> hidden layers, </span><span class="se">\n</span><span class="s2">&quot;</span> \
                        <span class="sa">f</span><span class="s2">&quot;with </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)</span><span class="si">}</span><span class="s2"> nodes, respectively. </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">multiline_str</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.activation">
<code class="codehilite language-python"><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.activation" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Non-linear activation function</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>x</code></td>
        <td><code>Tensor</code></td>
        <td><p>linear output from previous layer</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>alpha</code></td>
        <td><code>Tensor</code></td>
        <td><p>trainable parameter</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>beta</code></td>
        <td><code>Tensor</code></td>
        <td><p>trainable parameter</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tensor</code></td>
      <td><p>the result of applying the non-linear activation function to the linear output of the layer</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">activation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
               <span class="n">x</span><span class="p">,</span> 
               <span class="n">alpha</span><span class="p">,</span> 
               <span class="n">beta</span>
               <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Non-linear activation function</span>

<span class="sd">    Parameters:</span>
<span class="sd">        x (Tensor):</span>
<span class="sd">            linear output from previous layer</span>
<span class="sd">        alpha (Tensor):</span>
<span class="sd">            trainable parameter</span>
<span class="sd">        beta (Tensor):</span>
<span class="sd">            trainable parameter</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor:</span>
<span class="sd">            the result of applying the non-linear activation function to the linear output of the layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">x</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">beta</span><span class="p">))</span> <span class="p">),</span> <span class="n">x</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.compute_loss">
<code class="codehilite language-python"><span class="n">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_parameters</span><span class="p">,</span> <span class="n">training_features</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.compute_loss" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Mean squared difference</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>training_parameters</code></td>
        <td><code>Tensor</code></td>
        <td><p>input parameters</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>training_features</code></td>
        <td><code>Tensor</code></td>
        <td><p>true features</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tensor</code></td>
      <td><p>mean squared difference</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">training_parameters</span><span class="p">,</span>
                 <span class="n">training_features</span>
                 <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mean squared difference</span>

<span class="sd">    Parameters:</span>
<span class="sd">        training_parameters (Tensor):</span>
<span class="sd">            input parameters</span>
<span class="sd">        training_features (Tensor):</span>
<span class="sd">            true features</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor:</span>
<span class="sd">            mean squared difference</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">squared_difference</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictions_tf</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">),</span> <span class="n">training_features</span><span class="p">)))</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.compute_loss_and_gradients">
<code class="codehilite language-python"><span class="n">compute_loss_and_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_parameters</span><span class="p">,</span> <span class="n">training_features</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.compute_loss_and_gradients" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Computes mean squared difference and gradients</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>training_parameters</code></td>
        <td><code>Tensor</code></td>
        <td><p>input parameters</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>training_features</code></td>
        <td><code>Tensor</code></td>
        <td><p>true features</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>loss (Tensor)</code></td>
      <td><p>mean squared difference
gradients (Tensor):
    gradients</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">compute_loss_and_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                               <span class="n">training_parameters</span><span class="p">,</span>
                               <span class="n">training_features</span>
                               <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes mean squared difference and gradients</span>

<span class="sd">    Parameters:</span>
<span class="sd">        training_parameters (Tensor):</span>
<span class="sd">            input parameters</span>
<span class="sd">        training_features (Tensor):</span>
<span class="sd">            true features</span>

<span class="sd">    Returns:</span>
<span class="sd">        loss (Tensor):</span>
<span class="sd">            mean squared difference</span>
<span class="sd">        gradients (Tensor):</span>
<span class="sd">            gradients</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># compute loss on the tape</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>

        <span class="c1"># loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">squared_difference</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictions_tf</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">),</span> <span class="n">training_features</span><span class="p">)))</span> 

    <span class="c1"># compute gradients</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">gradients</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.dict_to_ordered_arr_np">
<code class="codehilite language-python"><span class="n">dict_to_ordered_arr_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.dict_to_ordered_arr_np" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Sort input parameters</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>input_dict</code></td>
        <td><code>dict [numpy.ndarray]</code></td>
        <td><p>input dict of (arrays of) parameters to be sorted</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>numpy.ndarray</code></td>
      <td><p>parameters sorted according to desired order</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">dict_to_ordered_arr_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                           <span class="n">input_dict</span><span class="p">,</span> 
                           <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sort input parameters</span>

<span class="sd">    Parameters:</span>
<span class="sd">        input_dict (dict [numpy.ndarray]):</span>
<span class="sd">            input dict of (arrays of) parameters to be sorted</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray:</span>
<span class="sd">            parameters sorted according to desired order</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">input_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">input_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">input_dict</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.forward_pass_np">
<code class="codehilite language-python"><span class="n">forward_pass_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters_arr</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.forward_pass_np" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Forward pass through the network to predict the output, 
fully implemented in Numpy</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>parameters_arr</code></td>
        <td><code>numpy.ndarray</code></td>
        <td><p>array of input parameters</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>numpy.ndarray</code></td>
      <td><p>output predictions</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">forward_pass_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                    <span class="n">parameters_arr</span>
                    <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass through the network to predict the output, </span>
<span class="sd">    fully implemented in Numpy</span>

<span class="sd">    Parameters:</span>
<span class="sd">        parameters_arr (numpy.ndarray):</span>
<span class="sd">            array of input parameters</span>

<span class="sd">    Returns:</span>
<span class="sd">      numpy.ndarray:</span>
<span class="sd">        output predictions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># forward pass through the network</span>
    <span class="n">act</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[(</span><span class="n">parameters_arr</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>

        <span class="c1"># linear network operation</span>
        <span class="n">act</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="c1"># pass through activation function</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">betas_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">betas_</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">*</span><span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="mf">1.</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">act</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span><span class="o">*</span><span class="n">act</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># final (linear) layer -&gt; (standardised) predictions</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># rescale and output</span>
    <span class="k">return</span> <span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.predictions_np">
<code class="codehilite language-python"><span class="n">predictions_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters_dict</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.predictions_np" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Predictions given input parameters collected in a dict.
Fully implemented in Numpy. Calls <code>forward_pass_np</code>
after ordering the input parameter dict</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>parameters_dict</code></td>
        <td><code>dict [numpy.ndarray]</code></td>
        <td><p>dictionary of (arrays of) parameters</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>numpy.ndarray</code></td>
      <td><p>output predictions</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predictions_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                   <span class="n">parameters_dict</span>
                   <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Predictions given input parameters collected in a dict.</span>
<span class="sd">    Fully implemented in Numpy. Calls ``forward_pass_np``</span>
<span class="sd">    after ordering the input parameter dict</span>

<span class="sd">    Parameters:</span>
<span class="sd">        parameters_dict (dict [numpy.ndarray]):</span>
<span class="sd">            dictionary of (arrays of) parameters</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray:</span>
<span class="sd">            output predictions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">parameters_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dict_to_ordered_arr_np</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_pass_np</span><span class="p">(</span><span class="n">parameters_arr</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.predictions_tf">
<code class="codehilite language-python"><span class="n">predictions_tf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters_tensor</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.predictions_tf" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Prediction given tensor of input parameters,
fully implemented in TensorFlow</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>parameters_tensor</code></td>
        <td><code>Tensor</code></td>
        <td><p>input parameters</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tensor</code></td>
      <td><p>output predictions</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">predictions_tf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                   <span class="n">parameters_tensor</span>
                   <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prediction given tensor of input parameters,</span>
<span class="sd">    fully implemented in TensorFlow</span>

<span class="sd">    Parameters:</span>
<span class="sd">        parameters_tensor (Tensor):</span>
<span class="sd">            input parameters</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor:</span>
<span class="sd">            output predictions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">parameters_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>

        <span class="c1"># linear network operation</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

        <span class="c1"># non-linear activation function</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

    <span class="c1"># linear output layer</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># rescale -&gt; output predictions</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_std</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.restore">
<code class="codehilite language-python"><span class="n">restore</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.restore" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Load pre-trained model</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>filename</code></td>
        <td><code>str</code></td>
        <td><p>filename tag (without suffix) where model was saved</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">restore</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
            <span class="n">filename</span>
            <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load pre-trained model</span>

<span class="sd">    Parameters:</span>
<span class="sd">        filename (str):</span>
<span class="sd">            filename tag (without suffix) where model was saved</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># load attributes</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;.pkl&quot;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas_</span><span class="p">,</span> \
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span><span class="p">,</span> \
        <span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span><span class="p">,</span> \
        <span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> \
        <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">modes</span><span class="p">,</span> \
        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.save">
<code class="codehilite language-python"><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.save" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Save network parameters</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>filename</code></td>
        <td><code>str</code></td>
        <td><p>filename tag (without suffix) where model will be saved</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
         <span class="n">filename</span>
         <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save network parameters</span>

<span class="sd">    Parameters:</span>
<span class="sd">        filename (str):</span>
<span class="sd">            filename tag (without suffix) where model will be saved</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># attributes</span>
    <span class="n">attributes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> 
                  <span class="bp">self</span><span class="o">.</span><span class="n">b_</span><span class="p">,</span> 
                  <span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span><span class="p">,</span> 
                  <span class="bp">self</span><span class="o">.</span><span class="n">betas_</span><span class="p">,</span> 
                  <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span><span class="p">,</span> 
                  <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">n_parameters</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">modes</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">]</span>

    <span class="c1"># save attributes to file</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;.pkl&quot;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">attributes</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.ten_to_predictions_np">
<code class="codehilite language-python"><span class="n">ten_to_predictions_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters_dict</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.ten_to_predictions_np" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>10^predictions given input parameters collected in a dict.
Fully implemented in Numpy. It raises 10 to the output
from <code>forward_pass_np</code></p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>parameters_dict</code></td>
        <td><code>dict [numpy.ndarray]</code></td>
        <td><p>dictionary of (arrays of) parameters</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>numpy.ndarray</code></td>
      <td><p>10^output predictions</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">ten_to_predictions_np</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                        <span class="n">parameters_dict</span>
                        <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    10^predictions given input parameters collected in a dict.</span>
<span class="sd">    Fully implemented in Numpy. It raises 10 to the output</span>
<span class="sd">    from ``forward_pass_np``</span>

<span class="sd">    Parameters:</span>
<span class="sd">        parameters_dict (dict [numpy.ndarray]):</span>
<span class="sd">            dictionary of (arrays of) parameters</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray:</span>
<span class="sd">            10^output predictions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">10.</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">predictions_np</span><span class="p">(</span><span class="n">parameters_dict</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.ten_to_predictions_tf">
<code class="codehilite language-python"><span class="n">ten_to_predictions_tf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters_tensor</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.ten_to_predictions_tf" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>10^predictions given tensor of input parameters,
fully implemented in TensorFlow. It raises 10 to the output
of <code>predictions_tf</code></p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>parameters_tensor</code></td>
        <td><code>Tensor</code></td>
        <td><p>input parameters</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tensor</code></td>
      <td><p>10^output predictions</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">ten_to_predictions_tf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                       <span class="n">parameters_tensor</span>
                       <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    10^predictions given tensor of input parameters,</span>
<span class="sd">    fully implemented in TensorFlow. It raises 10 to the output</span>
<span class="sd">    of ``predictions_tf``</span>

<span class="sd">    Parameters:</span>
<span class="sd">        parameters_tensor (Tensor):</span>
<span class="sd">            input parameters</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor:</span>
<span class="sd">            10^output predictions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictions_tf</span><span class="p">(</span><span class="n">parameters_tensor</span><span class="p">))</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.train">
<code class="codehilite language-python"><span class="n">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_parameters</span><span class="p">,</span> <span class="n">training_features</span><span class="p">,</span> <span class="n">filename_saved_model</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="mf">1e-05</span><span class="p">,</span> <span class="mf">1e-06</span><span class="p">],</span> <span class="n">batch_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">],</span> <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">patience_values</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">max_epochs</span><span class="o">=</span><span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">])</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.train" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Train the model</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>training_parameters</code></td>
        <td><code>dict [numpy.ndarray]</code></td>
        <td><p>input parameters</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>training_features</code></td>
        <td><code>numpy.ndarray</code></td>
        <td><p>true features for training</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>filename_saved_model</code></td>
        <td><code>str</code></td>
        <td><p>filename tag where model will be saved</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>validation_split</code></td>
        <td><code>float</code></td>
        <td><p>percentage of training data used for validation</p></td>
        <td><code>0.1</code></td>
      </tr>
      <tr>
        <td><code>learning_rates</code></td>
        <td><code>list [float]</code></td>
        <td><p>learning rates for each step of learning schedule</p></td>
        <td><code>[0.01, 0.001, 0.0001, 1e-05, 1e-06]</code></td>
      </tr>
      <tr>
        <td><code>batch_sizes</code></td>
        <td><code>list [int]</code></td>
        <td><p>batch sizes for each step of learning schedule</p></td>
        <td><code>[1024, 1024, 1024, 1024, 1024]</code></td>
      </tr>
      <tr>
        <td><code>gradient_accumulation_steps</code></td>
        <td><code>list [int]</code></td>
        <td><p>batches for gradient accumulations for each step of learning schedule</p></td>
        <td><code>[1, 1, 1, 1, 1]</code></td>
      </tr>
      <tr>
        <td><code>patience_values</code></td>
        <td><code>list [int]</code></td>
        <td><p>early stopping patience for each step of learning schedule</p></td>
        <td><code>[100, 100, 100, 100, 100]</code></td>
      </tr>
      <tr>
        <td><code>max_epochs</code></td>
        <td><code>list [int]</code></td>
        <td><p>maximum number of epochs for each step of learning schedule</p></td>
        <td><code>[1000, 1000, 1000, 1000, 1000]</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
          <span class="n">training_parameters</span><span class="p">,</span>
          <span class="n">training_features</span><span class="p">,</span>
          <span class="n">filename_saved_model</span><span class="p">,</span>
          <span class="c1"># cooling schedule</span>
          <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
          <span class="n">learning_rates</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">],</span>
          <span class="n">batch_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">],</span>
          <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
          <span class="c1"># early stopping set up</span>
          <span class="n">patience_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
          <span class="n">max_epochs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span>
         <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train the model</span>

<span class="sd">    Parameters:</span>
<span class="sd">        training_parameters (dict [numpy.ndarray]):</span>
<span class="sd">            input parameters</span>
<span class="sd">        training_features (numpy.ndarray):</span>
<span class="sd">            true features for training</span>
<span class="sd">        filename_saved_model (str):</span>
<span class="sd">            filename tag where model will be saved</span>
<span class="sd">        validation_split (float):</span>
<span class="sd">            percentage of training data used for validation</span>
<span class="sd">        learning_rates (list [float]):</span>
<span class="sd">            learning rates for each step of learning schedule</span>
<span class="sd">        batch_sizes (list [int]):</span>
<span class="sd">            batch sizes for each step of learning schedule</span>
<span class="sd">        gradient_accumulation_steps (list [int]):</span>
<span class="sd">            batches for gradient accumulations for each step of learning schedule</span>
<span class="sd">        patience_values (list [int]):</span>
<span class="sd">            early stopping patience for each step of learning schedule</span>
<span class="sd">        max_epochs (list [int]):</span>
<span class="sd">            maximum number of epochs for each step of learning schedule</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># check correct number of steps</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">)</span>\
           <span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">gradient_accumulation_steps</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">patience_values</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">),</span> \
           <span class="s1">&#39;Number of learning rates, batch sizes, gradient accumulation steps, patience values and max epochs are not matching!&#39;</span>

    <span class="c1"># training start info, if verbose</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="n">multiline_str</span> <span class="o">=</span> <span class="s2">&quot;Starting cosmopower_NN training, </span><span class="se">\n</span><span class="s2">&quot;</span> \
                        <span class="sa">f</span><span class="s2">&quot;using </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">validation_split</span><span class="p">)</span><span class="si">}</span><span class="s2"> per cent of training samples for validation. </span><span class="se">\n</span><span class="s2">&quot;</span> \
                        <span class="sa">f</span><span class="s2">&quot;Performing </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)</span><span class="si">}</span><span class="s2"> learning steps, with </span><span class="se">\n</span><span class="s2">&quot;</span> \
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)</span><span class="si">}</span><span class="s2"> learning rates </span><span class="se">\n</span><span class="s2">&quot;</span> \
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">)</span><span class="si">}</span><span class="s2"> batch sizes </span><span class="se">\n</span><span class="s2">&quot;</span> \
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">gradient_accumulation_steps</span><span class="p">)</span><span class="si">}</span><span class="s2"> gradient accumulation steps </span><span class="se">\n</span><span class="s2">&quot;</span> \
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">patience_values</span><span class="p">)</span><span class="si">}</span><span class="s2"> patience values </span><span class="se">\n</span><span class="s2">&quot;</span> \
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">)</span><span class="si">}</span><span class="s2"> max epochs </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">multiline_str</span><span class="p">)</span>

    <span class="c1"># from dict to array</span>
    <span class="n">training_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dict_to_ordered_arr_np</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">)</span>

    <span class="c1"># parameters standardisation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># features standardisation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">training_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">training_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># input parameters mean and std</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;parameters_mean&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;parameters_std&#39;</span><span class="p">)</span>

    <span class="c1"># (log)-spectra mean and std</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;features_mean&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_std</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;features_std&#39;</span><span class="p">)</span>

    <span class="c1"># training/validation split</span>
    <span class="n">n_validation</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">training_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">validation_split</span><span class="p">)</span>
    <span class="n">n_training</span> <span class="o">=</span> <span class="n">training_parameters</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">n_validation</span>

    <span class="c1"># casting</span>
    <span class="n">training_parameters</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">training_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">training_features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># train using cooling/heating schedule for lr/batch-size</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)):</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;learning rate = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;, batch size = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

        <span class="c1"># set learning rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="c1"># split into validation and training sub-sets</span>
        <span class="n">training_selection</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">([</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_training</span> <span class="o">+</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_validation</span><span class="p">)</span>

        <span class="c1"># create iterable dataset (given batch size)</span>
        <span class="n">training_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">training_parameters</span><span class="p">[</span><span class="n">training_selection</span><span class="p">],</span> <span class="n">training_features</span><span class="p">[</span><span class="n">training_selection</span><span class="p">]))</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">n_training</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="c1"># set up training loss</span>
        <span class="n">training_loss</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">infty</span><span class="p">]</span>
        <span class="n">validation_loss</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">infty</span><span class="p">]</span>
        <span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">infty</span>
        <span class="n">early_stopping_counter</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># loop over epochs</span>
        <span class="k">with</span> <span class="n">trange</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>
                <span class="c1"># loop over batches</span>
                <span class="k">for</span> <span class="n">theta</span><span class="p">,</span> <span class="n">feats</span> <span class="ow">in</span> <span class="n">training_data</span><span class="p">:</span>

                    <span class="c1"># training step: check whether to accumulate gradients or not (only worth doing this for very large batch sizes)</span>
                    <span class="k">if</span> <span class="n">gradient_accumulation_steps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_step</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">feats</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_step_with_accumulated_gradients</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">feats</span><span class="p">,</span> <span class="n">accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                <span class="c1"># compute validation loss at the end of the epoch</span>
                <span class="n">validation_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">[</span><span class="o">~</span><span class="n">training_selection</span><span class="p">],</span> <span class="n">training_features</span><span class="p">[</span><span class="o">~</span><span class="n">training_selection</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

                <span class="c1"># update the progressbar</span>
                <span class="n">t</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">validation_loss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                <span class="c1"># early stopping condition</span>
                <span class="k">if</span> <span class="n">validation_loss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
                    <span class="n">best_loss</span> <span class="o">=</span> <span class="n">validation_loss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">early_stopping_counter</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">early_stopping_counter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">early_stopping_counter</span> <span class="o">&gt;=</span> <span class="n">patience_values</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">update_emulator_parameters</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename_saved_model</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation loss = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">best_loss</span><span class="p">))</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model saved.&#39;</span><span class="p">)</span>
                    <span class="k">break</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_emulator_parameters</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename_saved_model</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Reached max number of epochs. Validation loss = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">best_loss</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model saved.&#39;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.training_step">
<code class="codehilite language-python"><span class="n">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_parameters</span><span class="p">,</span> <span class="n">training_features</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.training_step" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Minimize loss</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>training_parameters</code></td>
        <td><code>Tensor</code></td>
        <td><p>input parameters</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>training_features</code></td>
        <td><code>Tensor</code></td>
        <td><p>true features</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>loss (Tensor)</code></td>
      <td><p>mean squared difference</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                  <span class="n">training_parameters</span><span class="p">,</span>
                  <span class="n">training_features</span>
                  <span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Minimize loss</span>

<span class="sd">    Parameters:</span>
<span class="sd">        training_parameters (Tensor):</span>
<span class="sd">            input parameters</span>
<span class="sd">        training_features (Tensor):</span>
<span class="sd">            true features</span>

<span class="sd">    Returns:</span>
<span class="sd">        loss (Tensor):</span>
<span class="sd">            mean squared difference</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># compute loss and gradients</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">gradients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss_and_gradients</span><span class="p">(</span><span class="n">training_parameters</span><span class="p">,</span> <span class="n">training_features</span><span class="p">)</span>

    <span class="c1"># apply gradients</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.training_step_with_accumulated_gradients">
<code class="codehilite language-python"><span class="n">training_step_with_accumulated_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_parameters</span><span class="p">,</span> <span class="n">training_features</span><span class="p">,</span> <span class="n">accumulation_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.training_step_with_accumulated_gradients" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Minimize loss, breaking calculation into accumulated gradients</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>training_parameters</code></td>
        <td><code>Tensor</code></td>
        <td><p>input parameters</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>training_features</code></td>
        <td><code>Tensor</code></td>
        <td><p>true features</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>accumulation_steps</code></td>
        <td><code>int</code></td>
        <td><p>number of accumulated gradients</p></td>
        <td><code>10</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>accumulated_loss (Tensor)</code></td>
      <td><p>mean squared difference</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">training_step_with_accumulated_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                                             <span class="n">training_parameters</span><span class="p">,</span> 
                                             <span class="n">training_features</span><span class="p">,</span> 
                                             <span class="n">accumulation_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Minimize loss, breaking calculation into accumulated gradients</span>

<span class="sd">    Parameters:</span>
<span class="sd">        training_parameters (Tensor):</span>
<span class="sd">            input parameters</span>
<span class="sd">        training_features (Tensor):</span>
<span class="sd">            true features</span>
<span class="sd">        accumulation_steps (int):</span>
<span class="sd">            number of accumulated gradients</span>

<span class="sd">    Returns:</span>
<span class="sd">        accumulated_loss (Tensor):</span>
<span class="sd">            mean squared difference</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># create dataset to do sub-calculations over</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">training_parameters</span><span class="p">,</span> <span class="n">training_features</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">training_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">accumulation_steps</span><span class="p">))</span>

    <span class="c1"># initialize gradients and loss (to zero)</span>
    <span class="n">accumulated_gradients</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">variable</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">variable</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">]</span>
    <span class="n">accumulated_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># loop over sub-batches</span>
    <span class="k">for</span> <span class="n">training_parameters_</span><span class="p">,</span> <span class="n">training_features_</span><span class="p">,</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>

        <span class="c1"># calculate loss and gradients</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">gradients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss_and_gradients</span><span class="p">(</span><span class="n">training_parameters_</span><span class="p">,</span> <span class="n">training_features_</span><span class="p">)</span>

        <span class="c1"># update the accumulated gradients and loss</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">accumulated_gradients</span><span class="p">)):</span>
            <span class="n">accumulated_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">training_features_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">training_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">accumulated_loss</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="n">loss</span><span class="o">*</span><span class="n">training_features_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">training_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># apply accumulated gradients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">accumulated_gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">accumulated_loss</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 class="doc doc-heading" id="cosmopower.cosmopower_NN.cosmopower_NN.update_emulator_parameters">
<code class="codehilite language-python"><span class="n">update_emulator_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


<a class="headerlink" href="#cosmopower.cosmopower_NN.cosmopower_NN.update_emulator_parameters" title="Permanent link">&para;</a></h4>

    <div class="doc doc-contents ">

      <p>Update emulator parameters before saving them</p>

        <details class="quote">
          <summary>Source code in <code>cosmopower/cosmopower_NN.py</code></summary>
          <div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">update_emulator_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Update emulator parameters before saving them</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># put network parameters to numpy arrays</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W_</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b_</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">betas_</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>

    <span class="c1"># put mean and std parameters to numpy arrays</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_std</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_mean_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features_std_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_std</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../../contribute/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Contribute/Support/Community" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Contribute/Support/Community
            </div>
          </div>
        </a>
      
      
        
        <a href="../cosmopower_PCA-reference/" class="md-footer__link md-footer__link--next" aria-label="Next: cosmopower_PCA" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              cosmopower_PCA
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://github.com/alessiospuriomancini/cosmopower" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.bd0b6b67.min.js"}</script>
    
    
      <script src="../../assets/javascripts/bundle.8aa65030.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>